{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaseyPYZ/CaseyPYZ.github.io/blob/master/4_gemm_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# GEMM on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IcE4c-V5Psg"
      },
      "source": [
        "## 1. Set-up "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMbgGWP75Psg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94015b6d-42e0-4910-8212-d6139f6334cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "REpyYw1o5Psi"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xmVrYXr05Psi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ba090-cb0a-4b39-ce81-6ab871fef955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n",
            "/content/gdrive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-CaseyPYZ' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ece5545/a3-CaseyPYZ\n",
            "M\t1-conv1d_cpu.ipynb\n",
            "M\t2-conv1d_gpu.ipynb\n",
            "M\t4-gemm_gpu.ipynb\n",
            "M\t5-conv2d_dw_gpu.ipynb\n",
            "M\tsrc/ops.py\n",
            "M\ttests/test_dwsp_2dconv_gpu.py\n",
            "Already on 'main'\n",
            "Your branch is behind 'origin/main' by 6 commits, and can be fast-forwarded.\n",
            "  (use \"git pull\" to update your local branch)\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n",
            "From https://github.com/ML-HW-SYS/a3-CaseyPYZ\n",
            "   dfdfcf5..c675a72  main       -> origin/main\n",
            "Updating 7b5483e..c675a72\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\tsrc/ops.py\n",
            "\ttests/test_dwsp_2dconv_gpu.py\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ll4LScr_5Psi"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WdiSdTlu5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008f6cb2-32b8-434d-e963-9b7418790652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  src\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     tests\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDlW3_V5uX8"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VkqX6TEG5tz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71fca24-8b6f-4f37-f2b9-2f008a74d2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.7.dev1/tlcpack_nightly_cu102-0.9.dev1023%2Bgc7c76d194-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (402.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 402.4 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (5.4.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (1.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (1.21.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (5.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (21.4.0)\n",
            "Collecting synr==0.6.0\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from tlcpack-nightly-cu102) (1.3.0)\n",
            "Installing collected packages: synr, tlcpack-nightly-cu102\n",
            "Successfully installed synr-0.6.0 tlcpack-nightly-cu102-0.9.dev1023+gc7c76d194\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16GZ_We05Psj"
      },
      "source": [
        "## 3. Implement `make_conv1d_gpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then \n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_gpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array. \n",
        "You should return both the TVM scheduler and the TVM opterator for \n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2nIPEBHF5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da8ccc1-c96c-4671-851c-ac0cb941f21c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [[524.47034 503.88644 522.64484 ... 518.5747  528.0553  511.68924]\n",
            " [512.7203  503.0598  513.73535 ... 513.2929  516.8656  517.37463]\n",
            " [521.0815  503.4694  513.0932  ... 510.99936 520.9406  507.571  ]\n",
            " ...\n",
            " [514.8672  501.3088  514.41956 ... 513.7351  527.81195 516.0408 ]\n",
            " [519.7831  506.13788 518.90643 ... 516.3929  522.1201  512.5967 ]\n",
            " [512.98804 495.13617 512.2703  ... 510.44714 516.6054  509.73026]]\n",
            "Output: [[524.47015 503.88666 522.645   ... 518.5756  528.0554  511.6887 ]\n",
            " [512.72    503.06015 513.735   ... 513.293   516.8655  517.3749 ]\n",
            " [521.08105 503.4696  513.09296 ... 510.99927 520.9407  507.57065]\n",
            " ...\n",
            " [514.86755 501.309   514.419   ... 513.73505 527.81213 516.04083]\n",
            " [519.7829  506.13806 518.9063  ... 516.3928  522.1203  512.597  ]\n",
            " [512.98834 495.13617 512.27045 ... 510.44705 516.6056  509.73065]]\n",
            "GEMM GPU TVM: 123.759724 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"GEMM GPU TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjnf_oPi5Psk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3912bc-244c-486a-a7c2-07bfb4f5eb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [2097152], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [524288], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
            "  attr [IterVar(blockIdx.y: int32, (nullptr), \"ThreadIndex\", \"blockIdx.y\")] \"thread_extent\" = 1024;\n",
            "  attr [IterVar(blockIdx.x: int32, (nullptr), \"ThreadIndex\", \"blockIdx.x\")] \"thread_extent\" = 512 {\n",
            "    C[((blockIdx.y*512) + blockIdx.x)] = 0f32\n",
            "    for (k: int32, 0, 2048) {\n",
            "      C[((blockIdx.y*512) + blockIdx.x)] = (C[((blockIdx.y*512) + blockIdx.x)] + (A[((blockIdx.y*2048) + k)]*B[((k*512) + blockIdx.x)]))\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQiasz7n5Psk",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d058c611-14d6-434f-cbfb-0c95dd1b26f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-CaseyPYZ\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-3.6.4, py-1.11.0, pluggy-0.7.1\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-CaseyPYZ, inifile:\n",
            "plugins: typeguard-2.7.1\n",
            "collected 20 items                                                             \u001b[0m\n",
            "\n",
            "tests/test_gemm_gpu.py ....................\u001b[36m                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m========================== 20 passed in 25.60 seconds ==========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_gemm_gpu.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPT1: Blocking**"
      ],
      "metadata": {
        "id": "SCBvZJmoczGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(f\"GEMM GPU TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bFNwLEyicO",
        "outputId": "552aa549-fbe4-4e0a-b0a3-77c695f30caf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMM GPU TVM: 25.420097 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPT2: Virtual Thread Split**"
      ],
      "metadata": {
        "id": "WXmSWfmoyas4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(f\"GEMM GPU TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N54s7TJuqOls",
        "outputId": "fa157163-a44a-4e26-c85e-e729a3b07f12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMM GPU TVM: 17.610606 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPT3:**"
      ],
      "metadata": {
        "id": "L9vah7CPyjTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(f\"GEMM GPU TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ],
      "metadata": {
        "id": "JE7_iUBOyls8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "4-gemm_gpu.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}